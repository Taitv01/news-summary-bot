#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import feedparser
import json
import os
import logging
import time
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Set, Optional, Tuple
from dataclasses import dataclass
from contextlib import asynccontextmanager

from scraper import NewsScraper
from content_extractor import extract_content
from telegram_sender import send_telegram_message, escape_markdown_v2
from summarizer import summarize_with_gemini

# C·∫•u h√¨nh logging v·ªõi rotation ƒë·ªÉ tr√°nh file log qu√° l·ªõn
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Constants
MAX_ARTICLES_PER_SOURCE = 10
MESSAGE_LIMIT = 4000
DATA_DIR = 'data'
PROCESSED_LINKS_FILE = os.path.join(DATA_DIR, 'processed_links.json')
RSS_CONFIG_FILE = os.path.join(DATA_DIR, 'rss_sources.json')
RETRY_DELAY = 1
MAX_CONCURRENT_REQUESTS = 5

@dataclass
class Article:
    """C·∫•u tr√∫c d·ªØ li·ªáu cho b√†i b√°o."""
    title: str
    link: str
    content: Optional[str] = None

class ConfigManager:
    """Qu·∫£n l√Ω c·∫•u h√¨nh RSS t·ª´ file ho·∫∑c m·∫∑c ƒë·ªãnh."""
    
    @staticmethod
    def load_rss_sources() -> Dict[str, str]:
        """T·∫£i c√°c ngu·ªìn RSS t·ª´ file c·∫•u h√¨nh ho·∫∑c tr·∫£ v·ªÅ m·∫∑c ƒë·ªãnh."""
        if os.path.exists(RSS_CONFIG_FILE):
            try:
                with open(RSS_CONFIG_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, FileNotFoundError):
                logger.warning(f"Kh√¥ng th·ªÉ ƒë·ªçc file c·∫•u h√¨nh RSS. S·ª≠ d·ª•ng c·∫•u h√¨nh m·∫∑c ƒë·ªãnh.")
        
        # C·∫•u h√¨nh m·∫∑c ƒë·ªãnh
        default_sources = {
            'VnExpress M·ªõi nh·∫•t': 'https://vnexpress.net/rss/tin-moi-nhat.rss',
            'VnExpress Kinh doanh': 'https://vnexpress.net/rss/kinh-doanh.rss',
            'Vietstock Ch·ª©ng kho√°n': 'https://vietstock.vn/rss/chung-khoan.rss',
            'Lao ƒê·ªông': 'https://laodong.vn/rss/tin-moi-nhat.rss'
        }
        
        # T·∫°o file c·∫•u h√¨nh m·∫∑c ƒë·ªãnh
        ConfigManager._save_default_config(default_sources)
        return default_sources
    
    @staticmethod
    def _save_default_config(sources: Dict[str, str]) -> None:
        """L∆∞u c·∫•u h√¨nh m·∫∑c ƒë·ªãnh ra file."""
        os.makedirs(DATA_DIR, exist_ok=True)
        with open(RSS_CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(sources, f, ensure_ascii=False, indent=2)

class ProcessedLinksManager:
    """Qu·∫£n l√Ω danh s√°ch c√°c link ƒë√£ x·ª≠ l√Ω."""
    
    def __init__(self):
        self.processed_links: Set[str] = set()
    
    def load(self) -> Set[str]:
        """T·∫£i danh s√°ch c√°c link ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω."""
        if os.path.exists(PROCESSED_LINKS_FILE):
            try:
                with open(PROCESSED_LINKS_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.processed_links = set(data) if isinstance(data, list) else set()
                    return self.processed_links
            except (json.JSONDecodeError, FileNotFoundError):
                logger.warning(f"L·ªói ƒë·ªçc file {PROCESSED_LINKS_FILE}. B·∫Øt ƒë·∫ßu v·ªõi danh s√°ch r·ªóng.")
        
        self.processed_links = set()
        return self.processed_links
    
    def save(self) -> None:
        """L∆∞u danh s√°ch c√°c link ƒë√£ x·ª≠ l√Ω."""
        os.makedirs(DATA_DIR, exist_ok=True)
        try:
            with open(PROCESSED_LINKS_FILE, 'w', encoding='utf-8') as f:
                json.dump(list(self.processed_links), f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u processed links: {e}")
    
    def add(self, link: str) -> None:
        """Th√™m link v√†o danh s√°ch ƒë√£ x·ª≠ l√Ω."""
        self.processed_links.add(link)
    
    def contains(self, link: str) -> bool:
        """Ki·ªÉm tra link ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ch∆∞a."""
        return link in self.processed_links

class MessageSplitter:
    """Chia tin nh·∫Øn th√†nh c√°c ph·∫ßn nh·ªè h∆°n gi·ªõi h·∫°n."""
    
    @staticmethod
    def split_message(text: str, limit: int = MESSAGE_LIMIT) -> List[str]:
        """Chia m·ªôt ƒëo·∫°n vƒÉn b·∫£n d√†i th√†nh nhi·ªÅu ph·∫ßn nh·ªè h∆°n gi·ªõi h·∫°n."""
        if len(text) <= limit:
            return [text]
        
        parts = []
        remaining_text = text
        
        while remaining_text:
            if len(remaining_text) <= limit:
                parts.append(remaining_text)
                break
            
            # T√¨m v·ªã tr√≠ ng·∫Øt d√≤ng g·∫ßn nh·∫•t
            split_pos = remaining_text.rfind('\n', 0, limit)
            if split_pos == -1:
                split_pos = limit
            
            parts.append(remaining_text[:split_pos])
            remaining_text = remaining_text[split_pos:].lstrip()
        
        return parts

class RSSFetcher:
    """L·∫•y tin t·ª©c t·ª´ c√°c ngu·ªìn RSS."""
    
    def __init__(self, processed_links_manager: ProcessedLinksManager):
        self.processed_links_manager = processed_links_manager
    
    def fetch_new_articles(self, rss_sources: Dict[str, str]) -> List[Article]:
        """L·∫•y c√°c b√†i b√°o m·ªõi t·ª´ t·∫•t c·∫£ ngu·ªìn RSS."""
        new_articles = []
        
        for source_name, rss_url in rss_sources.items():
            logger.info(f"-> ƒêang l·∫•y t·ª´: {source_name}")
            try:
                feed = feedparser.parse(rss_url)
                if feed.bozo:
                    logger.warning(f"L·ªói parsing RSS t·ª´ {source_name}: {feed.bozo_exception}")
                    continue
                
                for entry in feed.entries[:MAX_ARTICLES_PER_SOURCE]:
                    if not self.processed_links_manager.contains(entry.link):
                        new_articles.append(Article(
                            title=entry.title,
                            link=entry.link
                        ))
            except Exception as e:
                logger.error(f"L·ªói khi l·∫•y RSS t·ª´ {source_name}: {e}")
                continue
        
        return new_articles

class ContentProcessor:
    """X·ª≠ l√Ω n·ªôi dung b√†i b√°o."""
    
    def __init__(self, scraper: NewsScraper, processed_links_manager: ProcessedLinksManager):
        self.scraper = scraper
        self.processed_links_manager = processed_links_manager
    
    def process_articles_concurrent(self, articles: List[Article]) -> List[Article]:
        """X·ª≠ l√Ω nhi·ªÅu b√†i b√°o song song ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô."""
        successful_articles = []
        
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT_REQUESTS) as executor:
            # T·∫°o future cho m·ªói b√†i b√°o
            future_to_article = {
                executor.submit(self._process_single_article, article): article 
                for article in articles
            }
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            for future in as_completed(future_to_article):
                article = future_to_article[future]
                try:
                    processed_article = future.result()
                    if processed_article and processed_article.content:
                        successful_articles.append(processed_article)
                        self.processed_links_manager.add(processed_article.link)
                except Exception as e:
                    logger.error(f"L·ªói x·ª≠ l√Ω b√†i b√°o {article.link}: {e}")
        
        return successful_articles
    
    def _process_single_article(self, article: Article) -> Optional[Article]:
        """X·ª≠ l√Ω m·ªôt b√†i b√°o duy nh·∫•t."""
        try:
            response = self.scraper.get_content_with_retry(article.link)
            if response and response.status_code == 200:
                content = extract_content(response.text, article.link)
                if content:
                    article.content = f"TI√äU ƒê·ªÄ: {article.title}\nN·ªòI DUNG:\n{content}"
                    return article
        except Exception as e:
            logger.error(f"L·ªói khi x·ª≠ l√Ω b√†i b√°o {article.link}: {e}")
        
        return None

class TelegramMessageSender:
    """G·ª≠i tin nh·∫Øn Telegram."""
    
    def __init__(self):
        self.message_splitter = MessageSplitter()
    
    def send_summary(self, summary: str) -> None:
        """G·ª≠i t√≥m t·∫Øt tin t·ª©c qua Telegram."""
        try:
            # X·ª≠ l√Ω k√Ω t·ª± ƒë·∫∑c bi·ªát cho n·ªôi dung AI
            escaped_content = escape_markdown_v2(summary)
            
            # Th√™m ti√™u ƒë·ªÅ
            full_message = f"üì∞ *B·∫¢N TIN T·ªîNG H·ª¢P H√îM NAY*\n\n{escaped_content}"
            
            # Chia tin nh·∫Øn th√†nh c√°c ph·∫ßn nh·ªè
            message_chunks = self.message_splitter.split_message(full_message)
            
            for i, chunk in enumerate(message_chunks):
                message_to_send = chunk
                
                # Th√™m ghi ch√∫ ph·∫ßn n·∫øu c√≥ nhi·ªÅu h∆°n 1 ph·∫ßn
                if len(message_chunks) > 1:
                    note = escape_markdown_v2(f"\n\n(Ph·∫ßn {i+1}/{len(message_chunks)})")
                    message_to_send += note
                
                send_telegram_message(message_to_send)
                time.sleep(RETRY_DELAY)
                
        except Exception as e:
            logger.error(f"L·ªói khi g·ª≠i tin nh·∫Øn Telegram: {e}")

class NewsBot:
    """Bot t√≥m t·∫Øt tin t·ª©c ch√≠nh."""
    
    def __init__(self):
        self.scraper = NewsScraper()
        self.processed_links_manager = ProcessedLinksManager()
        self.rss_fetcher = RSSFetcher(self.processed_links_manager)
        self.content_processor = ContentProcessor(self.scraper, self.processed_links_manager)
        self.telegram_sender = TelegramMessageSender()
    
    def run(self) -> None:
        """Ch·∫°y quy tr√¨nh x·ª≠ l√Ω tin t·ª©c ch√≠nh."""
        logger.info("--- Bot t√≥m t·∫Øt tin t·ª©c b·∫Øt ƒë·∫ßu ch·∫°y ---")
        
        try:
            # T·∫£i danh s√°ch link ƒë√£ x·ª≠ l√Ω
            self.processed_links_manager.load()
            
            # T·∫£i c·∫•u h√¨nh RSS
            rss_sources = ConfigManager.load_rss_sources()
            logger.info("ƒêang ki·ªÉm tra tin t·ª©c t·ª´ t·∫•t c·∫£ c√°c ngu·ªìn RSS...")
            
            # L·∫•y b√†i b√°o m·ªõi
            new_articles = self.rss_fetcher.fetch_new_articles(rss_sources)
            
            if not new_articles:
                logger.info("Kh√¥ng c√≥ b√†i b√°o m·ªõi.")
                return
            
            logger.info(f"Ph√°t hi·ªán {len(new_articles)} b√†i b√°o m·ªõi. B·∫Øt ƒë·∫ßu thu th·∫≠p n·ªôi dung...")
            
            # X·ª≠ l√Ω n·ªôi dung b√†i b√°o song song
            processed_articles = self.content_processor.process_articles_concurrent(new_articles)
            
            if not processed_articles:
                logger.warning("Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c n·ªôi dung t·ª´ b·∫•t k·ª≥ b√†i b√°o m·ªõi n√†o.")
                return
            
            logger.info(f"ƒê√£ thu th·∫≠p {len(processed_articles)} b√†i b√°o. T·∫°o t√≥m t·∫Øt...")
            
            # G·ªôp n·ªôi dung v√† t√≥m t·∫Øt
            combined_text = "\n\n---H·∫æT B√ÄI B√ÅO---\n\n".join(
                article.content for article in processed_articles
            )
            
            final_summary = summarize_with_gemini(combined_text)
            
            logger.info("ƒê√£ nh·∫≠n t√≥m t·∫Øt t·ª´ AI. G·ª≠i tin nh·∫Øn...")
            
            # G·ª≠i tin nh·∫Øn
            self.telegram_sender.send_summary(final_summary)
            
        except Exception as e:
            logger.error(f"L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
        
        finally:
            # L∆∞u danh s√°ch link ƒë√£ x·ª≠ l√Ω
            self.processed_links_manager.save()
            self.scraper.close()
            logger.info("--- Ho√†n t·∫•t chu k·ª≥. ---")

def main():
    """H√†m ch√≠nh."""
    try:
        bot = NewsBot()
        bot.run()
    except KeyboardInterrupt:
        logger.info("Bot b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
    except Exception as e:
        logger.error(f"L·ªói kh√¥ng mong mu·ªën: {e}")

if __name__ == "__main__":
    main()
