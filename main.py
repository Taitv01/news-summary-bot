import os
import requests
import feedparser
import google.generativeai as genai
from bs4 import BeautifulSoup
import random

# --- C·∫§U H√åNH ---
PROCESSED_LINKS_FILE = 'processed_links.txt'

# L·∫•y th√¥ng tin nh·∫°y c·∫£m t·ª´ GitHub Secrets (s·∫Ω ƒë∆∞·ª£c truy·ªÅn v√†o d∆∞·ªõi d·∫°ng bi·∫øn m√¥i tr∆∞·ªùng)
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# Danh s√°ch c√°c ngu·ªìn c·∫•p RSS tin t·ª©c
RSS_FEEDS = [
    {'name': 'VnExpress M·ªõi nh·∫•t', 'url': 'https://vnexpress.net/rss/tin-moi-nhat.rss'},
    {'name': 'VnExpress Kinh doanh', 'url': 'https://vnexpress.net/rss/kinh-doanh.rss'},
    {'name': 'Vietstock Ch·ª©ng kho√°n', 'url': 'https://vietstock.vn/830/chung-khoan/co-phieu.rss'},
    {'name': 'Lao ƒê·ªông', 'url': 'https://laodong.vn/rss/tin-moi-nhat.rss'}
]
MAX_ARTICLES_PER_DIGEST = 10

# **FIX:** Danh s√°ch c√°c User-Agent ƒë·ªÉ xoay v√≤ng, gi·∫£ d·∫°ng nhi·ªÅu tr√¨nh duy·ªát kh√°c nhau
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',
]

# --- C√ÅC H√ÄM L∆ØU TR·ªÆ (ƒê·ªçc/ghi file c·ª•c b·ªô) ---

def load_processed_links():
    if not os.path.exists(PROCESSED_LINKS_FILE):
        return set()
    with open(PROCESSED_LINKS_FILE, 'r', encoding='utf-8') as f:
        return set(line.strip() for line in f)

def save_processed_links(links_set):
    with open(PROCESSED_LINKS_FILE, 'w', encoding='utf-8') as f:
        for link in sorted(list(links_set)):
            f.write(link + '\n')

# --- C√ÅC H√ÄM CH·ª®C NƒÇNG ---

def get_all_news_from_rss(feeds):
    print("ƒêang ki·ªÉm tra tin t·ª©c t·ª´ t·∫•t c·∫£ c√°c ngu·ªìn RSS...")
    all_articles = []
    for feed_info in feeds:
        try:
            print(f"  -> ƒêang l·∫•y t·ª´: {feed_info['name']}")
            # S·ª≠ d·ª•ng m·ªôt User-Agent ng·∫´u nhi√™n khi l·∫•y RSS feed
            feed = feedparser.parse(feed_info['url'], agent=random.choice(USER_AGENTS))
            for entry in feed.entries[:10]:
                all_articles.append({
                    'title': entry.title,
                    'link': entry.link,
                    'source': feed_info['name']
                })
        except Exception as e:
            print(f"L·ªói khi l·∫•y tin t·ª´ {feed_info['name']}: {e}")
    return all_articles


def scrape_article_content(url):
    print(f"ƒêang l·∫•y n·ªôi dung t·ª´: {url}")
    try:
        # **FIX:** N√¢ng c·∫•p b·ªô headers v√† xoay v√≤ng User-Agent
        headers = {
            'User-Agent': random.choice(USER_AGENTS),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Referer': 'https://www.google.com/',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'DNT': '1'
        }
        
        response = requests.get(url, timeout=30, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # **FIX:** B·ªï sung th√™m nhi·ªÅu selector h∆°n n·ªØa ƒë·ªÉ t√¨m n·ªôi dung
        selectors = [
            "article.fck_detail",           # VnExpress (c·∫•u tr√∫c c≈©)
            "div.sidebar-1",                # VnExpress (c·∫•u tr√∫c m·ªõi)
            "div#article-content",          # Vietstock
            "div.content-detail",           # Vietstock (c·∫•u tr√∫c kh√°c)
            "div.post-content",             # C·∫•u tr√∫c blog chung
            "div.entry-content",            # C·∫•u tr√∫c blog chung
            "div.td-post-content",          # C·∫•u tr√∫c b√°o ch√≠
            "div.article-content",          # C·∫•u tr√∫c chung
            "div.singular-content",         # Lao ƒê·ªông
            "div[data-testid='article-body']", # US News
            "main article"                  # C·∫•u tr√∫c HTML5 chung
        ]
        article_body = None
        for selector in selectors:
            article_body = soup.select_one(selector)
            if article_body: 
                print(f"  -> T√¨m th·∫•y n·ªôi dung v·ªõi selector: '{selector}'")
                break
        
        if article_body:
            # Lo·∫°i b·ªè c√°c th·∫ª kh√¥ng mong mu·ªën
            for unwanted_tag in article_body.select('div, figure, table, script, style, aside, .ad-placeholder, .related-news'):
                unwanted_tag.decompose()
            
            paragraphs = article_body.find_all('p')
            
            # N·∫øu kh√¥ng t√¨m th·∫•y th·∫ª <p>, th·ª≠ l·∫•y to√†n b·ªô text
            if not paragraphs:
                content_text = article_body.get_text(separator='\n', strip=True)
                return content_text
            
            return "\n".join([p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)])
            
        print(f"  [C·∫¢NH B√ÅO] Kh√¥ng t√¨m th·∫•y selector ph√π h·ª£p cho trang: {url}")
        return None
    except requests.exceptions.RequestException as e:
        print(f"L·ªói k·∫øt n·ªëi ho·∫∑c timeout khi l·∫•y n·ªôi dung: {e}")
        return None
    except Exception as e:
        print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi l·∫•y n·ªôi dung: {e}")
        return None

def generate_digest_with_gemini(all_articles_content):
    if not all_articles_content: return None
    print("ƒêang g·ª≠i n·ªôi dung t·ªïng h·ª£p ƒë·∫øn Gemini ƒë·ªÉ t·∫°o b·∫£n tin...")
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = f"""
        B·∫°n l√† m·ªôt bi√™n t·∫≠p vi√™n b√°o ch√≠ chuy√™n nghi·ªáp, c√≥ nhi·ªám v·ª• t·∫°o ra m·ªôt b·∫£n tin t·ªïng h·ª£p cho k√™nh Telegram t·ª´ nhi·ªÅu ngu·ªìn tin t·ª©c ti·∫øng Vi·ªát v√† ti·∫øng Anh.

        **Nhi·ªám v·ª•:**
        1.  ƒê·ªçc v√† ph√¢n t√≠ch t·∫•t c·∫£ c√°c b√†i b√°o ƒë∆∞·ª£c cung c·∫•p.
        2.  **QUAN TR·ªåNG: N·∫øu m·ªôt b√†i b√°o ƒë∆∞·ª£c vi·∫øt b·∫±ng ti·∫øng Anh, h√£y d·ªãch nh·ªØng √Ω ch√≠nh sang ti·∫øng Vi·ªát tr∆∞·ªõc khi t√≥m t·∫Øt.**
        3.  Ch·ªçn ra kho·∫£ng 3 ƒë·∫øn 5 tin t·ª©c quan tr·ªçng, n·ªïi b·∫≠t v√† ƒë√°ng ch√∫ √Ω nh·∫•t t·ª´ T·∫§T C·∫¢ c√°c ngu·ªìn.
        4.  V·ªõi M·ªñI tin t·ª©c ƒë√£ ch·ªçn, h√£y t√≥m t·∫Øt l·∫°i b·∫±ng ti·∫øng Vi·ªát theo ƒê√öNG c·∫•u tr√∫c sau (bao g·ªìm c·∫£ t√™n ngu·ªìn):
            `<b>üî• [Vi·∫øt m·ªôt ti√™u ƒë·ªÅ tin t·ª©c th·∫≠t h·∫•p d·∫´n b·∫±ng ti·∫øng Vi·ªát]</b>\n<i>[T√≥m t·∫Øt s√∫c t√≠ch n·ªôi dung ch√≠nh b·∫±ng ti·∫øng Vi·ªát trong 2-3 c√¢u]</i>\n(Ngu·ªìn: [T√™n ngu·ªìn c·ªßa b√†i b√°o ƒë√≥])`
        5.  S·∫Øp x·∫øp c√°c tin ƒë√£ t√≥m t·∫Øt theo m·ª©c ƒë·ªô quan tr·ªçng gi·∫£m d·∫ßn (tin n√≥ng nh·∫•t, quan tr·ªçng nh·∫•t l√™n ƒë·∫ßu).
        6.  K·∫øt h·ª£p t·∫•t c·∫£ th√†nh m·ªôt tin nh·∫Øn duy nh·∫•t cho Telegram. B·∫Øt ƒë·∫ßu tin nh·∫Øn b·∫±ng ti√™u ƒë·ªÅ ch√≠nh: `‚òÄÔ∏è B·∫¢N TIN T·ªîNG H·ª¢P ‚òÄÔ∏è`.
        7.  Ph√¢n t√°ch m·ªói m·ª•c tin t·ª©c b·∫±ng m·ªôt d√≤ng `---`.

        **Y√™u c·∫ßu ƒë·∫ßu ra:**
        - To√†n b·ªô ƒë·∫ßu ra ph·∫£i b·∫±ng ti·∫øng Vi·ªát.
        - Ch·ªâ tr·∫£ v·ªÅ DUY NH·∫§T tin nh·∫Øn ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng ho√†n ch·ªânh cho Telegram.
        - Kh√¥ng th√™m b·∫•t k·ª≥ l·ªùi ch√†o h·ªèi, l·ªùi gi·∫£i th√≠ch, hay ghi ch√∫ n√†o kh√°c.

        **N·ªòI DUNG C√ÅC B√ÄI B√ÅO C·∫¶N X·ª¨ L√ù:**
        ---
        {all_articles_content}
        ---
        """
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print(f"L·ªói khi g·ªçi Gemini API: {e}")
        return None

def send_message_to_telegram(message):
    print("ƒêang g·ª≠i b·∫£n tin t·ªïng h·ª£p ƒë·∫øn Telegram...")
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {'chat_id': TELEGRAM_CHAT_ID, 'text': message, 'parse_mode': 'HTML'}
    try:
        response = requests.post(url, data=payload, timeout=20)
        if response.status_code == 200:
            print("G·ª≠i b·∫£n tin th√†nh c√¥ng!")
        else:
            print(f"G·ª≠i b·∫£n tin th·∫•t b·∫°i. Status: {response.status_code}, Response: {response.text}")
    except Exception as e:
        print(f"L·ªói khi g·ª≠i tin nh·∫Øn Telegram: {e}")


# --- H√ÄM CH√çNH ---
def main():
    if not all([TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, GEMINI_API_KEY]):
        print("L·ªñI: Thi·∫øu m·ªôt trong c√°c secrets c·∫ßn thi·∫øt.")
        return
        
    print("--- Bot t√≥m t·∫Øt tin t·ª©c b·∫Øt ƒë·∫ßu ch·∫°y ---")
    processed_links = load_processed_links()
    print(f"ƒê√£ t·∫£i {len(processed_links)} links ƒë√£ x·ª≠ l√Ω.")
    
    articles = get_all_news_from_rss(RSS_FEEDS)
    new_articles = [article for article in articles if article['link'] not in processed_links]

    if not new_articles:
        print("Kh√¥ng c√≥ b√†i b√°o n√†o m·ªõi.")
    else:
        print(f"Ph√°t hi·ªán {len(new_articles)} b√†i b√°o m·ªõi. B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        random.shuffle(new_articles)
        articles_to_process = new_articles[:MAX_ARTICLES_PER_DIGEST]
        full_content_for_digest = ""
        links_in_this_batch = []
        for article in articles_to_process:
            content = scrape_article_content(article['link'])
            if content:
                full_content_for_digest += f"--- NGU·ªíN: {article['source']} ---\nB√ÄI B√ÅO: {article['title']}\nLINK: {article['link']}\nN·ªòI DUNG:\n{content}\n\n"
                links_in_this_batch.append(article['link'])
        if full_content_for_digest:
            digest_message = generate_digest_with_gemini(full_content_for_digest)
            if digest_message:
                send_message_to_telegram(digest_message)
                processed_links.update(links_in_this_batch)
                save_processed_links(processed_links)
                print("L∆∞u l·∫°i file processed_links.txt")
        else:
            print("Kh√¥ng l·∫•y ƒë∆∞·ª£c n·ªôi dung t·ª´ c√°c b√†i b√°o m·ªõi.")

    print("--- Ho√†n t·∫•t chu k·ª≥. ---")

if __name__ == "__main__":
    main()
